<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>Gao's LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet'
        type='text/css'>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/small_logo.png">
</head>

<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
    <div class="navigation"></div>

    <div class="news top-container">
        <div class="container-fluid">
            <div id="primarycontent">
                <center>
                    <h2>ShanghaiTech-Kujiale Indoor 360° dataset</h2>
                </center>
                
                <center>
                    <h3>
                        <a href="http://www.shanghaitech.edu.cn" target="_blank">ShanghaiTech University</a>, 
                        <a href="https://www.kujiale.com/" target="_blank">Kujiale.com</a>
                    </h3>
                </center>
                
                <center>
                    <h3>
                        <a href="https://www.dropbox.com/s/z66q4o9d11kgu29/indoor_360.zip?dl=0" target="_blank" style="color: #990000">[Download(DropBox)]</a>
                    </h3>
                </center>
                
                <center>
                    <img src="/img/dataset/indoor_360/dataset.png" width="1000">
                </center>

                    <h2>Introduction</h2>

                    <p>
                        To facilitate a performance evaluation for spherical indoor images, we also build a synthetic dataset. Our dataset contains a total of 1775 rooms with 3550 images. Each room corresponds to two images: with furniture or without furniture. This synthetic dataset contains RGB omnidirectional images, their corresponding depth, corners, plane-plane intersection lines and planes (room layout). We use a similar rendering technique following <a href="https://structured3d-dataset.org/" target="_blank">Structured3D</a> and provides with/without furniture pairs. Besides depth estimation, our dataset can also be used to empty room synthesis from a furnished room and layout estimation. 
                    </p>

                    <center>
                        <img src="/img/dataset/indoor_360/distribution.png" width="800">
                    </center>

                    <p>
                        Details of the Shanghaitech-Kujiale Indoor 360° dataset as shown above. (a) and (b) The comparison of the distributions in terms of the depth distances and the difference of depth within the same image between our synthetic dataset and the Stanford 2D-3D-S dataset.
                    </p>

                    <h2>Dataset Format</h2>
                    Train/test splits are provided in train.txt/test.txt. Each line corresponds to one idx. 
                    <br>
                    There are a total of 5 folders, where:
                    <li>boundary: boundary maps.</li>
                    <li>corner: corner maps.</li>
                    <li>cor_idx: corner coordinates.</li>
                    <li>plane: plane maps.</li>
                    <li>image: idx_empty->room without furniture, idx_full->room with furniture.</li>
                    <li>depth: idx_empty_depth->depth for room without furniture, idx_full->depth for room with furniture.
                        <br>
                        The Depth map is stored as uint16 bit single-channel images. During training and testing, we divide the depth value by 325 so that the depth value is within a realistic range.
                    </li>

                    <h2>Citation</h2>
                    If you find this useful, please cite our work as follows:
<pre>
@InProceedings{jin2020geometric,
title={Geometric Structure Based and Regularized Depth Estimation From 360$\degree$ Indoor Imagery},
author={Lei Jin, Yanyu Xu, Jia Zheng, Junfei Zhang, Rui Tang, Shugong Xu, Jingyi Yu, Shenghua Gao},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition},
year={2020}
}</pre>
                    <h2>Reference</h2>
<pre>
@inproceedings{Structured3D,
  title     = {Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling},
  author    = {Jia Zheng and Junfei Zhang and Jing Li and Rui Tang and Shenghua Gao and Zihan Zhou},
  booktitle = {Proceedings of The European Conference on Computer Vision (ECCV)}),
  year      = {2020}
}</pre>
                    
                    <h2>Acknowledgements</h2>
                    We would like to thank <a href="www.kujiale.com/" target="_blank" style="color: #990000">Kujiale.com</a> for providing the database of house designs and the rendering engine.
            </div>
        </div>
    </div>

    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>

</body>

</html>
