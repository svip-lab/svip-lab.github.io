<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>Shanghaitech Vision and Intelligent Perception(SVIP) LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet'
        type='text/css'>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/small_logo.png">
</head>

<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
    <div class="navigation"></div>

    <div class="news top-container">
        <div class="container-fluid">
            <div id="primarycontent">
                <center>
                    <h2>Chemical Sequence Verification Dataset</h2>
                </center>
                <center>
                    <h3>
                        <a href="http://www.shanghaitech.edu.cn" target="_blank">ShanghaiTech University</a>
                    </h3>
                </center>
                <center>
                    <h3>
                        <a href="https://shanghaitecheducn-my.sharepoint.com/:f:/g/personal/qianych_shanghaitech_edu_cn/EjHfzFTQyWxGuuHsR26u3ncBMYsyiD06foNe4x47-DrfLA?e=cfgL2N" target="_blank" style="color: #990000">[Download(OneDrive)]</a>
                        <a href="https://pan.baidu.com/s/1gYYhigjoQjw2OaeZFPwY9g" target="_blank" style="color: #990000">[Download(BaiduNetDisk, extraction code: 9uyk)]</a>
                    </h3>
                </center>
                <center>
                    <img src="/img/dataset/CSV_dataset/task.png" width="1000">
                </center>
                <p></p>


                <p>
                    <h2>Introduction</h2>

                    <div style="font-size:14px">
                        <p>This dataset is proposed to support the <strong>Sequence Verification</strong> task which aims
                            to distinguish positive video pairs performing the same action sequence from negative ones with
                            step-level transformations but still conducting the same task. The above figure demonstrates
                            specific examples of our task: there are 3 step-sequences (<i>seq1, seq2, seq3</i>) included while
                            <i>seq1</i> and <i>seq2</i> contain identical steps in the same order which leads <i>(seq1, seq2)</i>
                            to be a matching pair; while <i>seq2</i> and <i>seq3</i> are not only different in the order of steps,
                            but also in the number of steps, making <i>(seq2, seq3)</i> a dismatching pair.
                        </p>



                    </div>

                    <h2>Dataset Format</h2>
                    <p>
                        The CSV dataset contains 960,458 frames of over 1940 videos across 70 different kinds of procedures.
                        On average, each video lasts 20.58 seconds, contains 495.85 frames, and consists of 9.53 steps.
                    </p>


                    <center>
                        <img src="/img/dataset/CSV_dataset/CSV_statistics1.png" width="800">
                    </center>
<!--                    <img src="/img/dataset/CSV/CSV_statistics1.png" width="700">-->

                    <br>
                    <p>
                        As shown in the above figure, CSV includes 18 atomic-level actions with different frequencies, among which <strong>take</strong>
                        and <strong>put</strong> are the two most common actions. This makes sense since taking up or putting down
                        something are extremely common in reality. The videosâ€™ length varies from 5.63s to 58.43s due to the diversity
                        in complexity among procedures and individual differences of participants, such as movement habits, the memory of
                        the step sequence as well as familiarity with the operations. By interacting one action with different objects,
                        we have 106 steps in total (listed in the figure below).
                    </p>



                    <center>
                        <img src="/img/dataset/CSV_dataset/CSV_statistics2.png" width="1000">
                    </center>

                    <br>
                    Label info:
                    <li>The labels follow the from of <strong>A.B</strong> where <strong>A</strong> indicates the task and <strong>B</strong>
                    indicates one of the procedures of task <strong>A</strong>.</li>
                    <li>The realistic annotation for labels can be found in <i>label_bank.json</i> in the <a href="https://github.com/svip-lab/SVIP-Sequence-VerIfication-for-Procedures-in-Videos/tree/main/Datasets/CSV">github repo</a> .</li>

                    <h2>Citation</h2>
                    If you find this useful, please cite our work as follows:

                    <pre>
@article{qian2021svip,
  title={SVIP: Sequence VerIfication for Procedures in Videos},
  author={Qian, Yicheng and Luo, Weixin and Lian, Dongze and Tang, Xu and Zhao, Peilin and Gao, Shenghua},
  journal={arXiv preprint arXiv:2112.06447},
  year={2021}
}
</pre>
                </p>
            </div>
        </div>
    </div>

    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>

</body>

</html>
