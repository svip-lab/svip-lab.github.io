<!DOCTYPE html>
<html lang="en">

<head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="index, follow">
    
        <title>Shanghaitech Vision and Intelligent Perception(SVIP) LAB</title>
        <meta name="description" content="">
        <link rel="alternate" type="application/rss+xml" href="/feed.xml">
    
        <!-- Stylesheet -->
        <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>
    
    
        <!-- Google Fonts -->
        <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet' type='text/css'>
    
        <!-- Favicon -->
        <link rel="shortcut icon" href="/img/small_logo.png">
    
        <style type="text/css">
            .container-fluid .items {
                border: 1px solid #EEEEEE;
                padding: 10px;
                margin-bottom: 15px;
            }
    
            .card {
                height: 400px;
                overflow: hidden;
            }
    
            .card img {
                width: auto;
                height: auto;
                top: 50%;
                -webkit-transform: translateY(-50%);
                -ms-transform: translateY(-50%);
                -moz-transform: translateY(-50%);
                position: relative;
            }
    
            .card-title {
                font-size: 20px;
                font-weight: bold;
            }
    
            .card-content {
                height: 80px;
                width: 1000px;
                display: table-cell;
                vertical-align: middle;
                text-align: center;
                
            }
        </style>
</head>


<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
        <div class="navigation"></div>


    <div class="news top-container">
        <div class="container-fluid">
            <div id="primarycontent">
                <center>
                    <h2>Multi-view Multi-task Gaze Prediction with Deep Convolutional Neural Networks</h2>
                </center>
                <center>
                    <h3>
                        <a href="">Dongze Lian</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Shenghua Gao</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Lina Hu</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Weixin Luo</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Yanyu Xu</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Lixin Duan</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Jingyi Yu</a>
                    </h3>
                </center>
                <center>
                    <h3>
                        <a href="http://www.shanghaitech.edu.cn" target="_blank">ShanghaiTech University</a>
                    </h3>
                </center>
                <center>
                    <h3 style="color: #000000">In TNNLS 2018</h2>
                </center>
                <!-- <center>
                    <h3>
                        <a href="https://arxiv.org/abs/1712.09867" target="_blank" style="color: #990000">[Paper]</a>
                        <a href="https://github.com/StevenLiuWen/ano_pred_cvpr2018" target="_blank" style="color: #990000">[Code (Tensorflow)]</a>
                    </h3>
                </center> -->
                <center>
                    <img src="../img/project/tnnls2018_liandz1_2.png" width="800">
                </center>
                <p></p>


                <p>
                    <h2>Abstract</h2>

                    <div style="font-size:14px">
                        <p>Gaze estimation which aims to predict gaze points given eye images is an important task in computer
                            vision because of its applications in human visual attention understanding. Many existing methods
                            are based on single camera, and most of them only focus on either gaze point estimation or gaze
                            direction estimation. In this paper, we propose a novel multi-task method for gaze point estimation
                            by using multi-view cameras. Specifically, we analyze the close relationship between the gaze
                            point estimation and gaze direction estimation, and we use a partially shared convolutional neural
                            networks architecture to simultaneously estimate gaze direction and gaze point. Further, we also
                            introduce a new multi-view gaze tracking dataset which consists of multi-view eye images of different
                            subjects. As far as we know, it is the largest multi-view gaze tracking dataset. Comprehensive
                            experiments on our multi-view gaze tracking dataset and existing datasets demonstrate that our
                            multi-view multi-task gaze point estimation solution consistently outperforms existing methods.
                        </p>
                    </div>

                    <!-- <h2>Citation</h2>
                    If you find this useful, please cite our work as follows:

                    <pre>
@inproceedings{luo2017remembering,
    title={Remembering history with convolutional lstm for anomaly detection},
    author={Luo, Weixin and Liu, Wen and Gao, Shenghua},
    booktitle={Multimedia and Expo (ICME), 2017 IEEE International Conference on},
    pages={439--444},
    year={2017},
    organization={IEEE}
    }</pre> -->
                </p>
            </div>
            <!-- disqus -->
            <br>
            <hr/>
            <div id="disqus_thread"></div>
            <script>
                /**
                 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
                 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

                (function () { // DON'T EDIT BELOW THIS LINE
                    var d = document,
                        s = d.createElement('script');
                    s.src = 'https://shanghaitechcvdl.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                })();
            </script>
            <noscript>Please enable JavaScript to view the
                <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
            </noscript>
        </div>
    </div>

    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>
</body>

</html>