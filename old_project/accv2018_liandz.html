<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>Shanghaitech Vision and Intelligent Perception(SVIP) LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>


    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet' type='text/css'>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/small_logo.png">
</head>


<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
    <div class="navigation"></div>


    <div class="news top-container">
        <div class="container-fluid">
            <div id="primarycontent">
                <center>
                    <h2>Believe It or Not, We Know What You Are Looking at!</h2>
                </center>
                <center>
                    <h3>
                        <a href="">Dongze Lian</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Zehao Yu</a>&nbsp;&nbsp;&nbsp;
                        <a href="">Shenghua Gao</a>
                    </h3>
                </center>
                <center>
                    <h3>
                        <a href="http://www.shanghaitech.edu.cn" target="_blank">ShanghaiTech University</a>
                    </h3>
                </center>
                <center>
                    <h3 style="color: #000000">In ACCV 2018</h2>
                </center>
                <!-- <center>
                    <h3>
                        <a href="https://arxiv.org/abs/1712.09867" target="_blank" style="color: #990000">[Paper]</a>
                        <a href="https://github.com/StevenLiuWen/ano_pred_cvpr2018" target="_blank" style="color: #990000">[Code (Tensorflow)]</a>
                    </h3>
                </center> -->
                <center>
                    <img src="../img/project/accv2018_gaze.png" width="1000">
                </center>
                <p></p>


                <p>
                    <h2>Abstract</h2>

                    <div style="font-size:14px">
                        By borrowing the wisdom of human in gaze following, we propose a two-stage solution for gaze
                        point prediction of the target persons in a scene. Specifically, in the first stage, both head
                        image and its position are fed into a gaze direction pathway to predict the gaze direction, and
                        then multi-scale gaze direction fields are generated to characterize the distribution of gaze
                        points without considering the scene contents. In the second stage, the multi-scale gaze
                        direction fields are concatenated with the image contents and fed into a heatmap pathway for
                        heatmap regression. There are two merits for our two-stage solution based gaze following: i)
                        our solution mimics the behavior of human in gaze following, therefore it is more psychological
                        plausible; ii) besides using heatmap to supervise the output of our network, we can also
                        leverage gaze direction to facilitate the training of gaze direction pathway, therefore our
                        network can be more robustly trained. Considering that existing gaze following dataset is
                        annotated by the third-view persons, we build a video gaze following dataset, where the ground
                        truth is annotated by the observers in the videos. Therefore it is more reliable. The
                        evaluation with such a dataset reflects the capacity of different methods in real scenarios
                        better. Extensive experiments on both datasets show that our method significantly outperforms
                        existing methods, which validates the effectiveness of our solution for gaze following. Our
                        dataset and codes are released in https://github.com/svip-lab/GazeFollowing.
                </p>
            </div>

            <!-- <h2>Citation</h2>
                    If you find this useful, please cite our work as follows:

                    <pre>
@INPROCEEDINGS{xu2018gaze, 
        author={Yanyu Xu and Yanbing Dong and Junru Wu and Zhengzhong Sun and Zhiru Shi and Jingyi Yu  and Shenghua Gao}, 
        booktitle={2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
        title={Gaze Prediction in Dynamic 360 Immersive Videos}, 
        year={2018} 
}</pre> -->
            </p>
        </div>

        <!-- disqus -->
        <br>
        <hr />
        <div id="disqus_thread"></div>
        <script>
            /**
             *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
             *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

            (function () { // DON'T EDIT BELOW THIS LINE
                var d = document,
                    s = d.createElement('script');
                s.src = 'https://shanghaitechcvdl.disqus.com/embed.js';
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
        <noscript>Please enable JavaScript to view the
            <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>

    </div>
    </div>


    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>
</body>

</html>