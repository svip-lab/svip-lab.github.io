s<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>Shanghaitech Vision and Intelligent Perception(SVIP) LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet'
        type='text/css'>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/small_logo.png">
</head>

<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
    <div class="navigation"></div>
    <div class="news top-container">
        <div class="container-fluid">
            <div class="post">
                
                <h2>Selected Conference Papers</h2>
                <hr />
                <!-- CVPR 2023 Xu, Gao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2023_xujl.png">
                        </div>

                        <h4 class="media-heading">
                            Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models <br>
                            <small>Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2023</font>
                            </strong>
                            <br>
                            <a href="https://bluestyle97.github.io/dream3d/" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2212.14704" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- CVPR 2023 Dong, Gao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2023_dongsx.jpg">
                        </div>

                        <h4 class="media-heading">
                            Weakly Supervised Video Representation Learning with Unaligned Text for Sequential Videos<br>
                            <small>Sixun Dong<sup>*</sup>, Huazhang Hu<sup>*</sup>, Dongze Lian, Weixin Luo, Yicheng Qian, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2023</font>
                            </strong>
                            <br>
                            <a href="https://github.com/svip-lab/WeakSVR" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2303.12370" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- CVPR 2023 Wang, Gao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2023_wangry.jpg">
                        </div>

                        <h4 class="media-heading">
                            PlaneDepth: Self-supervised Depth Estimation via Orthogonal Planes <br>
                            <small>Ruoyu Wang, Zehao Yu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2023</font>
                            </strong>
                            <br>
                            <a href="https://github.com/svip-lab/PlaneDepth" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2210.01612" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                
                <!-- 3DV 2022 Zhi -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/3dv2022_ds-nerf.jpg">
                        </div>

                        <h4 class="media-heading">
                            Dual-Space NeRF: Learning Animatable Avatars and Scene Lighting in Separate Spaces <br>
                            <small>Yihao Zhi*, Shenhan Qian*, Xinhao Yan*, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">3DV 2022</font>
                            </strong>
                            <br>
                            <a href="https://shenhanqian.github.io/ds-nerf" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2208.14851" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://youtu.be/2qk4WOO8YMw" target="_blank" style="color: #990000">[Video]</a>
                            <a href="https://github.com/zyhbili/Dual-Space-NeRF" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- ECCV 2022 Qian -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img\project\eccv2022_qianshh.jpeg">
                        </div>

                        <h4 class="media-heading">
                            UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation <br>
                            <small>Shenhan Qian, Jiale Xu, Ziwei Liu, Liqian Ma, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2022</font>
                            </strong>
                            <br>
                            <a href="https://shenhanqian.github.io/unif" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2207.09835" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://youtu.be/2w4sYMLFHKM" target="_blank" style="color: #990000">[Video]</a>
                            <a href="https://github.com/ShenhanQian/UNIF" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- CVPR 2022 Qian, Luo, Lian, Gao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img\project\cvpr2022_qianych.png">
                        </div>

                        <h4 class="media-heading">
                            SVIP: Sequence VerIfication for Procedures in Videos <br>
                            <small>Yicheng Qian, Weixin Luo, Dongze Lian, Xu Tang, Peilin Zhao, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2022</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/2112.06447.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/SVIP-Sequence-VerIfication-for-Procedures-in-Videos" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img\project\cvpr2022_chenxn.png">
                        </div>

                        <h4 class="media-heading">
                            DearKD: Data-Efficient Early Knowledge Distillation for Vision Transformers <br>
                            <small> Xianing Chen, Qiong Cao, Yujie Zhong, Jing Zhang, Shenghua Gao, Dacheng Tao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2022</font>
                            </strong>
                            <br>
                            <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.html" target="_blank" style="color: #990000">[Paper]</a>
                            <!-- <a href="https://github.com/svip-lab/SVIP-Sequence-VerIfication-for-Procedures-in-Videos" target="_blank" style="color: #990000">[Code]</a> -->
                        </small>
                    </div>
                </div>
                <hr />

                <!-- CVPR 2022 Hu, Dong, Zhao, Lian, Li, Gao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img\project\cvpr2022_Hu_Dong.png">
                        </div>

                        <h4 class="media-heading">
                            TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting <br>
                            <small>Huazhang Hu<sup>*</sup>, Sixun Dong<sup>*</sup>, Yiqun Zhao, Dongze Lian, Zhengxin Li, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2022 Oral Presentation</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/abs/2204.01018" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/SvipRepetitionCounting/TransRAC" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr /> 

                <!-- ICLR 2022 lian dong ze -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img\project\iclr2022_liandz.png">
                        </div>
                        <h4 class="media-heading">
                            AS-MLP: An Axial Shifted MLP Architecture for Vision <br>
                            <small>Dongze Lian<sup>*</sup>, Zehao Yu<sup>*</sup>, Xing Sun, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICLR 2022 </font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/2107.08391.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/AS-MLP" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr /> 


                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/iccv2021_xuyy.png">
                        </div>

                        <h4 class="media-heading">
                            Crowd Counting With Partial Annotations in an Image <br>
                            <small>Yanyu Xu<sup>*</sup>, Ziming Zhong<sup>*</sup>, Dongze Lian, Jin Li, Zhengxin Li, Xinxing Xu, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICCV 2021</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />  
                
                <!-- ICCV 2021 Shenhan Qian -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/iccv2021_qianshh.png">
                        </div>

                        <h4 class="media-heading">
                            Speech Drives Templates: Co-Speech Gesture Synthesis with Learned Templates <br>
                            <small> Shenhan Qian<sup>*</sup>, Zhi Tu<sup>*</sup>, Yihao Zhi<sup>*</sup>, Wen Liu, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICCV 2021</font>
                            </strong>
                            <br>
                            <a href="https://shenhanqian.github.io/sdt" target="_blank" style="color: #990000">[Project]</a>
                            <a href="https://arxiv.org/abs/2108.08020" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://youtu.be/yu-5gUHn6h8" target="_blank" style="color: #990000">[Video]</a>
                            <a href="https://github.com/ShenhanQian/SpeechDrivesTemplates" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />  
                
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/MICCAI2021_xuyy.png">
                        </div>

                        <h4 class="media-heading">
                            Partially-Supervised Learning for Vessel Segmentation in Ocular Images
                            <br>
                            <small> Yanyu Xu, Xinxing Xu, Lei Jin, Shenghua Gao, Rick Siow Mong Goh</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">MICCAI 2021</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/IROS2021_xuyy.png">
                        </div>

                        <h4 class="media-heading">
                            Accurate depth estimation from a hybrid  event-RGB stereo setup
                            <br>
                            <small> Yi-Fan Zuo, Li Cui, Xin Peng, Yanyu Xu, Shenghua Gao, Xia Wang, Laurent Kneip</small>
                        </h4>
                        <small>Accepted by
                            <strong>
                                <font color="red">IROS 2021</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2021_huangbb.png">
                        </div>

                        <h4 class="media-heading">
                            Look Before You Leap: Learning Landmark Features For One-Stage Visual Grounding
                            <br>
                            <small>Binbin Huang, Dongze Lian, Weixin Luo, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2021</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/abs/2104.04386" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/LBYLNet" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />
                
                <!-- CVPR 2021 IVOS-W -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2021_ivos.png">
                        </div>

                        <h4 class="media-heading">
                            Learning to Recommend Frame for Interactive Video Object Segmentation in the Wild
                            <br>
                            <small>Zhaoyuan Yin, Jia Zheng, Weixin Luo, Shenhan Qian, Hanling Zhang, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2021</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/abs/2103.10391" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/IVOS-W" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />
                
                <!-- CVPR 2021 PNVS -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2021_xujl.png">
                        </div>

                        <h4 class="media-heading">
                            Layout-Guided Novel View Synthesis from a Single Indoor Panorama
                            <br>
                            <small>Jiale Xu, Jia Zheng, Yanyu Xu, Rui Tang, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2021</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/abs/2103.17022" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/bluestyle97/PNVS" target="_blank" style="color: #990000">[Project]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- CVPR 2021 Zibo Zhao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2021_zhaozb.png">
                        </div>

                        <h4 class="media-heading">
                            Prior Based Human Completion
                            <br>
                            <small>Zibo Zhao, Wen Liu, Yanyu Xu, Xianing Chen, Weixin Luo, Lei Jin, Bohui Zhu, Tong Liu, Binqiang Zhao, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2021</font>
                            </strong>
                            <br>
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Prior_Based_Human_Completion_CVPR_2021_paper.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/Maikouuu/PBHC" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/aaai_zhanghao.jpg">
                        </div>

                        <h4 class="media-heading">
                            Appearance-Motion Memory Consistency Network for Video Anomaly Detection
                            <br>
                            <small>Ruichu Cai, Hao Zhang, Wen Liu, Shenghua Gao, Zhifeng Hao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2021</font>
                            </strong>
                        </small>
                    </div>
                </div>
                <hr />  

                <!-- AAAI 2021 Shenhan Qian -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/aaai2021_qianshh.png">
                        </div>

                        <h4 class="media-heading">
                            KGDet: Keypoint-Guided Fashion Detection
                            <br>
                            <small>Shenhan Qian<sup>*</sup>, Dongze Lian<sup>*</sup>, Binqiang Zhao, Tong Liu, Bohui Zhu, Hai Li, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2021</font>
                            </strong>
                            <br>
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/16346" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/ShenhanQian/KGDet" target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />  

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/YutingXiao-AAAI-2021.png">
                        </div>

                        <h4 class="media-heading">
                            Amodal Segmentation Based on Visible Region Segmentation and Shape Prior
                            <br>
                            <small>Yuting Xiao, Yanyu Xu, Ziming Zhong, Weixin Luo, Jiawei Li, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2021</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/2012.05598.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/YutingXiao/Amodal-Segmentation-Based-on-Visible-Region-Segmentation-and-Shape-Prior" target="_blank"
                               style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />  

                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/nips2020.png">
                        </div>

                        <h4 class="media-heading">
                            SIRI: Spatial Relation Induced Network For Spatial Description Resolution
                            <br>
                            <small>Peiyao Wang<sup>*</sup>, Weixin Luo<sup>*</sup>, Yanyu Xu, Haojie Li, Shugong Xu, Jianyu Yang, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">NeurIPS 2020</font>
                            </strong>
                            <br>
                            <a href="http://arxiv.org/abs/2010.14301" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                <hr /> 

                <!-- ECCV 2020_yuzh -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/eccv2020_yuzh.png">
                        </div>

                        <h4 class="media-heading">
                            P2Net: Patch-match and Plane-regularization for Unsupervised Indoor Depth Estimation
                            <br>
                            <small>Zehao Yu<sup>*</sup>, Lei Jin<sup>*</sup>, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2020</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/2007.07696.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/Indoor-SfMLearner" target="_blank" style="color: #990000">[Code]</a>                           
                        </small>
                    </div>
                </div>
                <hr />  
                
                <!-- ECCV 2020_zk -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/eccv_zhoukang.png">
                        </div>

                        <h4 class="media-heading">
                            Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images
                            <br>
                            <small>Kang Zhou<sup>*</sup>, Yuting Xiao<sup>*</sup>, Jianlong Yang, Jun Cheng, Wen Liu, Weixin Luo, Zaiwang Gu, Jiang Liu, Shenghua Gao. </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2020</font>
                            </strong>
                            <br>
                            <a href="https://github.com/ClancyZhou/P_Net_Anomaly_Detection" target="_blank" style="color: #990000">[Code]</a>    
                            <a href="http://zhoukang.pro/video/eccv.mp4" target="_blank" style="color: #990000">[Video]</a>
                        </small>
                    </div>
                </div>
                <hr />  
                
                
                
                <!-- arxiv2019_zhengjia -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/arxiv2019_zhengjia.png">
                        </div>

                        <h4 class="media-heading">
                            Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling
                            <br>
                            <small>Jia Zheng<sup>*</sup>, Junfei Zhang<sup>*</sup>, Jing Li, Rui Tang, Shenghua Gao, Zihan Zhou </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2020</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1908.00222.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://drive.google.com/file/d/17F_jIfY_QKFNmsOSvzUFZwWKrr6YUMnQ" target="_blank"
                                style="color: #990000">[Supplemental Material]</a>
                            <a href="https://github.com/bertjiazheng/Structured3D" target="_blank"
                                style="color: #990000">[Code]</a>
                            <a href="https://structured3d-dataset.org/" target="_blank" style="color: #990000">[Website]</a>
                        </small>
                    </div>
                </div>
                <hr />
                

                <!--iclr2020_liandz -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/ICLR2020_liandz.png">
                            <br>
                            <br>
                        </div>

                        <h4 class="media-heading">
                            Towards Fast Adaptation of Neural Architectures with Meta Learning
                            <br>
                            <small>Dongze Lian, Yin Zheng, Yintao Xu, Yanxiong Lu, Leyu Lin, Peilin Zhao, Junzhou Huang, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICLR 2020</font>
                            </strong>
                            <br>
                            <a href="https://openreview.net/forum?id=r1eowANFvr" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                <hr />
                

                <!-- CVPR 2020_yuzh -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2020_yuzh.png">
                            <br>
                            <br>
                        </div>

                        <h4 class="media-heading">
                            Fast-MVSNet: Sparse-to-Dense Multi-View Stereo With Learned Propagation and Gauss-Newton Refinement
                            <br>
                            <small>Zehao Yu, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2020</font>
                            </strong>
                            <br>
                            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yu_Fast-MVSNet_Sparse-to-Dense_Multi-View_Stereo_With_Learned_Propagation_and_Gauss-Newton_Refinement_CVPR_2020_paper.pdf" target="_blank" 
                               style="color: #990000">[Paper]</a>
                            <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yu_Fast-MVSNet_Sparse-to-Dense_Multi-View_CVPR_2020_supplemental.pdf" target="_blank"
                               style="color: #990000">[Supplemental Material]</a>
                            <a href="https://github.com/svip-lab/FastMVSNet" target="_blank" 
                               style="color: #990000">[Code]</a>              
                        </small>
                    </div>
                </div>
                <hr />
                
                <!-- CVPR 2020_jinlei -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2020_jinlei.png">
                        </div>

                        <h4 class="media-heading">
                            Geometric Structure Based and Regularized Depth Estimation From 360 Indoor Imagery
                            <br>
                            <small>Lei Jin<sup>*</sup>, Yanyu Xu<sup>*</sup>, Jia Zheng, Junfei Zhang, Rui Tang, Shugong Xu, Jingyi Yu, Shenghua Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2020</font>
                            </strong>
                            <br>
                            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Jin_Geometric_Structure_Based_and_Regularized_Depth_Estimation_From_360_Indoor_CVPR_2020_paper.pdf" target="_blank" 
                               style="color: #990000">[Paper]</a>
                            <a href="https://svip-lab.github.io/dataset/indoor_360.html" target="_blank"
                               style="color: #990000">[Dataset]</a>
                        </small>
                    </div>
                </div>
                <hr />
                
                
                <!-- ISBI 2020_zhouk1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/isbi2020_zhouk.png">
                        </div>

                        <h4 class="media-heading">
                            Sparse-GAN: Sparsity-constrained Generative Adversarial Network for Retinal OCT Image Anomaly Detection
                            <br>
                            <small>Kang Zhou, Shenghua Gao, Jun Cheng, Zaiwang Gu, Huazhu Fu, Zhi Tu, Jianlong Yang, Yitian Zhao, Jiang Liu </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ISBI 2020</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- ISBI 2020_chai -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/isbi2020_chai.png">
                        </div>

                        <h4 class="media-heading">
                            Perceptual-assisted Adversarial Adaptation for Choroid Segmentation in Optical Coherence Tomography
                            <br>
                            <small>Zhenjie Chai<sup>*</sup>, Kang Zhou<sup>*</sup>, Jianlong Yang, Yuhui Ma, Zhi Chen, Shenghua Gao, Jiang Liu</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ISBI 2020</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- ISBI 2020_tuzhi -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/isbi2020_tuzhi.png">
                        </div>

                        <h4 class="media-heading">
                            SUNet: A Lesion Regularized Model for Simultaneous Diabetic Retinopathy and Diabetic Macular Edema Grading
                            <br>
                            <small>Zhi Tu, Shenghua Gao, Kang Zhou, Xianing Chen, Huazhu Fu, Zaiwang Gu, Jun Cheng, Zehao Yu, Jiang Liu</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ISBI 2020</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- ISBI 2020_xiao -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/isbi2020_xiao.png">
                        </div>

                        <h4 class="media-heading">
                            Open-Set OCT Image Recognition with Synthetic Learning
                            <br>
                            <small>Yuting Xiao, Shenghua Gao, Zhenjie Chai, Kang Zhou, Tianyang Zhang, Yitian Zhao, Jun Cheng, Jiang Liu</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ISBI 2020</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- iccv2019_liuwen -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="/project_img/impersonator/actor/woman/Sweaters-id_0000088807_4_full.jpg"
                                style="float:left" width="109">
                            <video muted autoplay="autoplay" loop="loop" class="aaa" width="109" style="float:left">
                                <source
                                    src="/project_img/impersonator/intro/motion_transfer/mixamo_0007_Sweaters-id_0000088807_4_full.mp4"
                                    type="video/mp4">
                            </video>

                        </div>

                        <h4 class="media-heading">
                            Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and
                            Novel View Synthesis
                            <br>
                            <small>Wen Liu<sup>*</sup>, Zhixin Piao<sup>*</sup>, Jie Min, Wenhan Luo, Lin Ma, Shenghua
                                Gao </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICCV 2019</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1909.12224.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="/project_img/impersonator/4701-supp.pdf" target="_blank"
                                style="color: #990000">[Supplemental Material]</a>
                            <a href="https://github.com/svip-lab/impersonator" target="_blank"
                                style="color: #990000">[Code]</a>
                            <a href="/project/impersonator.html" target="_blank" style="color: #990000">[Website]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- miccai2019_zhouk1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/miccai2019_zhouk1.png">
                        </div>

                        <h4 class="media-heading">
                            Ki-GAN: Knowledge Infusion Generative Adversarial Network for Photoacoustic Image
                            Reconstruction in vivo
                            <br>
                            <small>Hengrong Lan<sup>*</sup>, Kang Zhou<sup>*</sup>, Changchun Yang, Jun Cheng, Jiang
                                Liu, Shenghua Gao<sup>^</sup>, Fei Gao<sup>^</sup> </small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">MICCAI 2019</font>
                            </strong>
                            <br>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- acmmm2019_zhangzh1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/acmmm2019_zhangzh1.png">
                        </div>

                        <h4 class="media-heading">
                            Learning Semantics-aware Distance Map with Semantics Layering Network for Amodal Instance
                            Segmentation
                            <br>
                            <small>Ziheng Zhang<sup>*</sup>, Anpei Chen<sup>*</sup>, Ling Xie, Jingyi Yu, Shenghua
                                Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ACM MM 2019</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1905.12898.pdf" target="_blank"
                                style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- ijcai2019_liuwen1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/ijcai2019_liuwen1.png">
                        </div>

                        <h4 class="media-heading">
                            Margin Learning Embedded Prediction for Video Anomaly Detection with A Few Anomalies
                            <br>
                            <small>Wen Liu<sup>*</sup>, Weixin Luo<sup>*</sup>, Zhengxin Li, Peilin Zhao, Shenghua
                                Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">IJCAI 2019</font>
                            </strong>
                            <br>
                            <a href="https://www.ijcai.org/proceedings/2019/0419.pdf" target="_blank"
                                style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- icme2019_hujh1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/icme2019_hujh1.png">
                        </div>

                        <h4 class="media-heading">
                            FPN++: A SIMPLE BASELINE FOR PEDESTRIAN DETECTION
                            <br>
                            <small>Junhao Hu<sup>*</sup>, Lei Jin<sup>*</sup>, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICME 2019</font>
                            </strong>
                            <br>
                            <a href="paper/icme2019_hujh.pdf" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- cvpr2019_ziheng1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2019_zhangzh1.png">
                        </div>

                        <h4 class="media-heading">
                            PPGNet: Learning Point-Pair Graph for Line Segment Detection
                            <br>
                            <small>Ziheng Zhang<sup>*</sup>, Zhengxin Li<sup>*</sup>, Ning Bi, Jia Zheng, Jinlei Wang,
                                Kun Huang, Weixin Luo, Yanyu Xu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2019</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1905.03415.pdf" target="_blank"
                                style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/PPGNet" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- cvpr2019_liandz2 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2019_liandz2.png">
                        </div>

                        <h4 class="media-heading">
                            Local to Global Learning: Gradually Adding Classes for Training Deep Neural Networks
                            <br>
                            <small>Hao Cheng<sup>*</sup>, Dongze Lian<sup>*</sup>, Bowen Deng, Shenghua Gao, Tao Tan,
                                Yanlin Geng</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2019</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Cheng_Local_to_Global_Learning_Gradually_Adding_Classes_for_Training_Deep_CVPR_2019_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/piratehao/Local-to-Global-Learning-for-DNNs" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- cvpr2019_zehao1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2019_yuzh1.jpg">
                        </div>

                        <h4 class="media-heading">
                            Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding
                            <br>
                            <small>Zehao Yu<sup>*</sup>, Jia Zheng<sup>*</sup>, Dongze Lian, Zihan Zhou, Shenghua
                                Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2019</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1902.09777.pdf" target="_blank"
                                style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/PlanarReconstruction" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />


                <!-- cvpr2019_liandz1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2019_liandz1.png">
                        </div>

                        <h4 class="media-heading">
                            Density Map Regression Guided Detection Network for RGB-D Crowd Counting and Localization
                            <br>
                            <small>Dongze Lian<sup>*</sup>, Jing Li<sup>*</sup>, Jia Zheng, Weixin Luo, Shenghua
                                Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2019</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/RGBD-Counting" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- aaai2019_liandz1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/aaai2019_liandz.png">
                        </div>

                        <h4 class="media-heading">
                            RGBD Based Gaze Estimation via Multi-task CNN
                            <br>
                            <small>Dongze Lian<sup>*</sup>, Ziheng Zhang<sup>*</sup>, Weixin Luo, Lina Hu, Minye Wu,
                                Zechao Li, Jingyi Yu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2019</font>
                            </strong>
                            <br>
                            <a href="paper/aaai2019_liandz1.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/RGBD-Gaze" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- accv2018_liandz1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/accv2018_gaze.png">
                        </div>

                        <h4 class="media-heading">
                            Believe It or Not, We Know What You Are Looking at!
                            <br>
                            <small>Dongze Lian<sup>*</sup>, Zehao Yu<sup>*</sup>, Shenghua Gao</small>
                        </h4>

                        <small>Accepted as
                            <strong>
                                <font color="red">ACCV 2018 Oral Presentation (Accepted Rate: 4.6%)</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/pdf/1907.02364.pdf" target="_blank"
                                style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/GazeFollowing" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- eccv2018_liandz1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/eccv2018_cheng.png">
                        </div>

                        <h4 class="media-heading">
                            Evaluating Capability of Deep Neural Networks for
                            Image Classication via Information Plane
                            <br>
                            <small>Hao Cheng, Dongze Lian, Shenghua Gao, Yanlin Geng</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hao_Cheng_Evaluating_Capability_of_ECCV_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/piratehao/API-of-estimating-mutual-information-in-networks"
                                target="_blank" style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- eccv2018_zhangzh1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/eccv2018_zhangzh1.png">
                        </div>

                        <h4 class="media-heading">
                            Saliency Detection in 360 Videos
                            <br>
                            <small>Ziheng Zhang
                                <sup>*</sup>, Yanyu Xu
                                <sup>*</sup>
                                , Jingyi Yu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ziheng_Zhang_Saliency_Detection_in_ECCV_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/svip-lab/Saliency-Detection-in-360-Videos" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- cvpr2018_liuw1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2018_liuw1.png" width="1000">
                        </div>

                        <h4 class="media-heading">
                            Future Frame Prediction for Anomaly Detection - A New Baseline
                            <br>
                            <small>Wen Liu
                                <sup>*</sup>, Weixin Luo
                                <sup>*</sup>, Dongze Lian, Shenghua Gao</small>
                        </h4>


                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2018</font>
                            </strong>
                            <br>
                            <a href="https://arxiv.org/abs/1712.09867" target="_blank"
                                style="color: #990000">[Paper]</a>
                            <a href="https://github.com/StevenLiuWen/ano_pred_cvpr2018" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                    </div>
                </div>
                <hr />

                <!-- cvpr2018_xuyy1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2018_xuyy1.png" width="700">
                        </div>

                        <h4 class="media-heading">
                            Encoding Crowd Interaction with Deep Neural Network for Pedestrian Trajectory Prediction
                            <br>
                            <small>Yanyu Xu
                                <sup>*</sup>, Zhixin Piao
                                <sup>*</sup>, Shenghua Gao</small>
                        </h4>


                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/ShanghaiTechCVDL/CIDNN" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                        <br>

                    </div>
                </div>
                <hr />

                <!-- cvpr2018_xuyy2 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2018_xuyy2.png" width="800">
                        </div>
                        <h4 class="media-heading">
                            Gaze Prediction in Dynamic 360 Immersive Videos
                            <br>
                            <small>Yanyu Xu, Yanbing Dong, Junru Wu, Zhengzhong Sun, Zhiru Shi, Jingyi Yu, Shenghua
                                Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Gaze_Prediction_in_CVPR_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/xuyanyu-shh/VR-EyeTracking" target="_blank"
                                style="color: #990000">[Code]</a>

                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <!-- cvpr2018_wangzw -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2018_wangzw1.png" width="800">
                        </div>

                        <h4 class="media-heading">
                            Face Aging With Identity-Preserved Conditional Generative Adversarial Networks
                            <br>
                            <small>Zongwei Wang, Xu Tang, Weixin Luo, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Face_Aging_With_CVPR_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/dawei6875797/Face-Aging-with-Identity-Preserved-Conditional-Generative-Adversarial-Networks"
                                target="_blank" style="color: #990000">[Code]</a>
                        </small>
                        <br>

                    </div>
                </div>
                <hr />

                <!-- cvpr2018_huangk1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2018_huangk1.png" width="800">
                        </div>

                        <h4 class="media-heading">
                            Learning to Parse Wireframes in Images of Man-Made Environments
                            <br>
                            <small>Kun Huang, Yifan Wang, Zihan Zhou, Tianjiao Ding, Shenghua Gao, Yi Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2018</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Learning_to_Parse_CVPR_2018_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/huangkuns/wireframe" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                        <br>



                    </div>
                </div>
                <hr />

                <!-- iccv2017_luowx1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/iccv2017_luowx1.png" width="800">
                        </div>
                        <h4 class="media-heading">
                            A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework
                            <br>
                            <small>Weixin Luo
                                <sup>*</sup>, Wen Liu
                                <sup>*</sup>, Shenghua Gao</small>
                        </h4>


                        <small>Accepted by
                            <strong>
                                <font color="red">ICCV 2017</font>
                            </strong>
                            <br>
                            <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Luo_A_Revisit_of_ICCV_2017_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>

                        <br>
                    </div>
                </div>
                <hr />


                <!-- icme2017_luowx1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/icme2017_luowx1.png" width="1000">
                        </div>

                        <h4 class="media-heading">
                            Remembering History with Convolutional LSTM for
                            Anomaly Detection
                            <br>
                            <small>Weixin Luo
                                <sup>*</sup>, Wen Liu
                                <sup>*</sup>, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICME 2017</font>
                            </strong>
                            <strong>(Oral, 15% accept rate)</strong>
                            <br>
                            <a href="paper/icme2017_luowx.pdf" target="_blank" style="color: #990000">[Paper]</a>
                            <a href="https://github.com/zachluo/convlstm_anomaly_detection" target="_blank"
                                style="color: #990000">[Code]</a>
                        </small>
                        <br>

                    </div>
                </div>
                <hr />


                <!-- ijcai2017_xuyy1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/ijcai2017_xuyy1.png" width="1000">
                        </div>

                        <h4 class="media-heading">
                            Beyond Universal Saliency: Personalized Saliency
                            Prediction with Multi-task CNN
                            <br>
                            <small>Yanyu Xu, Nianyi Li, Junru Wu, Jingyi Yu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">IJCAI 2017</font>
                            </strong>
                            <strong>(Best Student Paper Run-upper)</strong>
                            <br>
                            <a href="https://pdfs.semanticscholar.org/aca8/c4a62ed6e590889f1e859d7bc79311fa6f4d.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                        <br>

                    </div>
                </div>
                <hr />

                <!-- eccvw2016_xuyy1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/eccvw2016_xuyy1.png" width="800">
                        </div>

                        <h4 class="media-heading">
                            Bi-Level Multi-Column Convolutional Neural Networks
                            for Facial Landmark Point Detection
                            <br>
                            <small>Yanyu Xu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ECCV 2016 Workshop</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <!-- cvpr2016_zhangyy -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/cvpr2016_zhangyy1.png" width="800">
                        </div>

                        <h4 class="media-heading">
                            <a href="project/cvpr2016_zhangyy1.html">Single-Image Crowd Counting via Multi-Column
                                Convolutional Neural Network</a>
                            <br>
                            <small>Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, Yi Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2016</font>
                            </strong>
                            <br>
                            <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhang_Single-Image_Crowd_Counting_CVPR_2016_paper.pdf"
                                target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />


                <h2>Selected Journal Papers</h2>
                <hr />
                <!-- tpami 2022 li -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tpami2022_lijing.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Feature Re-Representation and Reliable Pseudo Label Retraining for Cross-Domain Semantic Segmentation
                            <br>
                            <small>Jing Li, Kang Zhou, Shenhan Qian, Wen Li, Lixin Duan, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2022</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />


                <hr />
                <!-- tpami 2022 lian -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tpami2022_liandz.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Locating and Counting Heads in Crowds With a Depth Prior
                            <br>
                            <small>Dongze Lian, Xianing Chen, Jing Li, Weixin Luo, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2022</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <hr />
                <!-- tpami 2022 -->
                <div class="media">
                    <div class="media-body">
                        <!-- <div class="col-xs-3">
                            <img src="/img/project/tnnls2021_zhoukang.png"
                                style="float:left" width="109">
                        </div> -->
                        <div class="col-xs-3">
                            <img src="img/project/tpami2022_luowx.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Future Frame Prediction Network for Video Anomaly Detection
                            <br>
                            <small>Weixin Luo, Wen Liu, Dongze Lian, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2022</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <hr />
                <!-- tmi 2022 zhoukang -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tmi2021_zhoukang.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Proxy-bridged Image Reconstruction Network for Anomaly Detection in Medical Images
                            <br>
                            <small>Kang Zhou, Jing Li, Weixin Luo, Zhengxin Li, Jianlong Yang, Huazhu Fu, Jun Cheng, Jiang Liu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TMI 2022</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <hr />
                <!-- tnnls2021_zhoukang -->
                <div class="media">
                    <div class="media-body">
                        <!-- <div class="col-xs-3">
                            <img src="/img/project/tnnls2021_zhoukang.png"
                                style="float:left" width="109">
                        </div> -->
                        <div class="col-xs-3">
                            <img src="img/project/tnnls2021_zhoukang.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Memorizing Structure-Texture Correspondence for Image Anomaly Detection
                            <br>
                            <small>Kang Zhou
                                <sup>*</sup>, Jing Li
                                <sup>*</sup>, Yuting Xiao, Jianlong Yang, Jun Cheng, Wen Liu, Weixin Luo, Jiang Liu, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TNNLS 2021</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />
                
                <hr />
                <!-- tpami2021_xuyy -->
                <div class="media">
                    <div class="media-body">
                        <!-- <div class="col-xs-3">
                            <img src="/img/project/PAMI2021_xuyy.png"
                                style="float:left" width="109">
                        </div> -->
                        <div class="col-xs-3">
                            <img src="img/project/eccv2018_zhangzh1.png" width="1000">
                        </div>
                        <h4 class="media-heading">
                            Spherical DNNs and Their Applications in 360 Images and Videos
                            <br>
                            <small>Yanyu Xu
                                <sup>*</sup>, Ziheng Zhang
                                <sup>*</sup>, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2021</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />


                <hr />
                <!-- tpami2021_liuwen -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="/project_img/impersonator/actor/woman/Sweaters-id_0000088807_4_full.jpg"
                                style="float:left" width="109">
                            <video muted autoplay="autoplay" loop="loop" class="aaa" width="109" style="float:left">
                                <source
                                    src="/project_img/impersonator/intro/motion_transfer/mixamo_0007_Sweaters-id_0000088807_4_full.mp4"
                                    type="video/mp4">
                            </video>
                        </div>
                        <h4 class="media-heading">
                            Liquid Warping GAN with Attention: A Unified Framework for Human Image Synthesis
                            <br>
                            <small>Wen Liu
                                <sup>*</sup>, Zhixin Piao
                                <sup>*</sup>, Zhi Tu, Wenhan Luo, Lin Ma, Shenghua Gao</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2021</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />


                <!-- tpami2018_luowx1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tpami2018_luowx1.png" width="1000">
                        </div>


                        <h4 class="media-heading">
                            Video Anomaly Detection with Sparse Coding Inspired
                            Deep Neural Networks
                            <br>
                            <small>Weixin Luo
                                <sup>*</sup>, Wen Liu
                                <sup>*</sup>, Shenghua Gao, Dongze Lian</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2019</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <!-- tnnls2018_lianzd1 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tnnls2018_liandz1.png" width="1000">
                        </div>

                        <h4 class="media-heading">
                            Multi-view Multi-task Gaze Prediction with Deep
                            Convolutional Neural Networks
                            <br>
                            <small>Dongze Lian, Shenghua Gao, Lina Hu, Weixin Luo, Yanyu Xu, Lixin Duan, Jingyi
                                Yu</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TNNLS 2018</font>
                            </strong>
                        </small>
                        <br>
                    </div>
                </div>
                <hr />


                <!-- tpami2018_xuyy2 -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tpami2018_xuyy2.png" width="1000">
                        </div>


                        <h4 class="media-heading">
                            Multi-column CNN and its Applications for Crowd
                            Counting and Face Alignment
                            <br>
                            <small>Yanyu Xu, Shenghua Gao, Yingying Zhang, Yi Ma</small>
                        </h4>

                        <small>Submitted to
                            <strong>
                                <font color="red">IJCV 2018</font>
                            </strong>
                            (under review)
                        </small>
                        <br>
                    </div>
                </div>
                <hr />

                <!-- tpami2018_xuyy -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="img/project/tpami2018_xuyy1.png" width="1000">
                        </div>

                        <h4 class="media-heading">
                            Personalized Saliency and its Prediction
                            <br>
                            <small>Yanyu Xu, Junru Wu, Nianyi Li, Shenghua Gao, Jingyi Yu</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TPAMI 2018</font>
                            </strong>
                        </small>
                        <br>

                    </div>
                </div>
                <hr />

            </div>
        </div>
    </div>


    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>
</body>

</html>
